[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "llama-lime",
    "section": "",
    "text": "llama-lime is a cutting-edge toolkit designed for data scientists, machine learning practitioners, researchers, and AI enthusiasts. It provides powerful tools to analyze, explore, and explain complex models, including Large Language Models (LLMs), with transparency and ease."
  },
  {
    "objectID": "index.html#welcome-to-llama-lime-leveraging-large-models-for-analysis-and-local-interpretable-model-explanations",
    "href": "index.html#welcome-to-llama-lime-leveraging-large-models-for-analysis-and-local-interpretable-model-explanations",
    "title": "llama-lime",
    "section": "",
    "text": "llama-lime is a cutting-edge toolkit designed for data scientists, machine learning practitioners, researchers, and AI enthusiasts. It provides powerful tools to analyze, explore, and explain complex models, including Large Language Models (LLMs), with transparency and ease."
  },
  {
    "objectID": "index.html#what-we-offer",
    "href": "index.html#what-we-offer",
    "title": "llama-lime",
    "section": "üéØ What We Offer",
    "text": "üéØ What We Offer\nExploration: Dive into your data with our Explorer class, equipped with comprehensive tools for Exploratory Data Analysis (EDA). Understand your data‚Äôs underlying patterns, distributions, and relationships like never before. Explanation: Demystify AI with our Explainer class, offering robust explainability techniques such as SHAP and LIME. From text to vision, we support various domains and tasks."
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "llama-lime",
    "section": "üåü Features",
    "text": "üåü Features\nVersatility: Seamlessly integrate llama-lime with diverse models, including Neural Networks, Random Forests, Hugging Face Transformers, and more. Multimodal Support: Analyze and explain models across a wide range of tasks, including classification, object detection, summarization, and more. User-Centric: Enjoy llama-lime‚Äôs user-friendly and intuitive APIs, designed for both beginners and experts alike. Community-Driven: We value collaboration and innovation. Contribute, learn, and grow with the llama-lime community."
  },
  {
    "objectID": "index.html#how-to-get-started",
    "href": "index.html#how-to-get-started",
    "title": "llama-lime",
    "section": "üõ†Ô∏è How to Get Started",
    "text": "üõ†Ô∏è How to Get Started\nReady to explore the world of explainable AI? Check out our Getting Started Guide, Tutorials, and API Documentation to embark on your journey with llama-lime."
  },
  {
    "objectID": "index.html#join-the-community",
    "href": "index.html#join-the-community",
    "title": "llama-lime",
    "section": "ü§ù Join the Community",
    "text": "ü§ù Join the Community\nWe welcome contributions and collaboration. Whether you‚Äôre a seasoned professional or just starting in AI, there‚Äôs room for you in the llama-lime family. Visit our GitHub to connect, contribute, and innovate.\nüéâ Unlock the potential of AI with llama-lime. Explore, Explain, and Empower your models with transparency and confidence!"
  },
  {
    "objectID": "random_forest_explanation.html",
    "href": "random_forest_explanation.html",
    "title": "Explaining a Random Forest",
    "section": "",
    "text": "We‚Äôll start with a super easy example, the obligatory iris dataset with a random forest classifier. Below we set up the model using scikit-learn, everything so far should look very familiar.\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_iris\n\nnp.random.seed(123)\n\niris = load_iris()\nrandom_forest = RandomForestClassifier()\nSince we‚Äôll use GPT-4 for the tutorial, and because GPT-4 is very smart, it probably knows the iris dataset anyway. To trick it a little bit into thinking we have a new dataset, let‚Äôs just rename the features and ‚Äújumble‚Äù the data a bit.\nfeature_names = [\"length of table\", \"width of table\", \"length of dresser\", \"width of dresser\"]\nclass_names = [\"living room\", \"bedroom\", \"dining room\"]\n\nX = iris.data * 1.8182\ny = iris.target\nrandom_forest.fit(X, y)\n\nRandomForestClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier()"
  },
  {
    "objectID": "random_forest_explanation.html#explaining-the-model",
    "href": "random_forest_explanation.html#explaining-the-model",
    "title": "Explaining a Random Forest",
    "section": "Explaining the Model",
    "text": "Explaining the Model\nFrom here, we‚Äôve fit the model and we can run predictions against the model with new data.\n\nimport numpy as np\n\nnew_observation = np.random.rand(1, 4)\n\nnew_observation\n\narray([[0.12062867, 0.8263408 , 0.60306013, 0.54506801]])\n\n\n\nrandom_forest.predict_proba(new_observation)\n\narray([[0.96, 0.04, 0.  ]])\n\n\nNow we can say that the most likely class to which our new observation belongs is living room. Of course, from here, we have a lot of questions. And if we don‚Äôt then the people we show our models to sure will üòÖ.\nThe random forest in scikit has some nice utilities for helping to diagnose what our model is doing under the hood."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]